{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "training_file = \"./dataset/train.p\"\n",
    "validation_file= \"./dataset/valid.p\"\n",
    "testing_file = \"./dataset/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "image_shape = X_train[0].shape\n",
    "n_classes = np.unique(y_train).shape[0]\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y_train, n_classes, histtype='bar')\n",
    "plt.title(\"Classes Are Very Unevenly Distributed\")\n",
    "plt.xlabel(\"Traffic Sign Class\")\n",
    "plt.ylabel(\"Examples in Training Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load human readable class labels from csv and store in a dict\n",
    "import csv\n",
    "class_labels = {}\n",
    "with open('signnames.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    class_labels = {key: val for key, val in reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_class(X_data, y_labels=[], cmap=None,\n",
    "                    rows=1, cols=12, maxtitlelen=18, figsize=(15,1)):\n",
    "    \"\"\"\n",
    "    Convenience method to visualize sets of images. If a set of corresponding\n",
    "    class labels is passed, they will be printed along with the image.\n",
    "    \"\"\"\n",
    "    has_labels = len(y_labels) > 0\n",
    "    assert not has_labels or len(X_data) == len(y_labels)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, img in enumerate(X_data):\n",
    "        plt.subplot(rows, cols, i+1, xticks=[], yticks=[])\n",
    "        plt.imshow(img, interpolation=\"nearest\", cmap=cmap)\n",
    "        if has_labels:\n",
    "            y_val = y_labels[i]\n",
    "            y_label = class_labels[str(y_val)][:maxtitlelen]\n",
    "            plt.title(\"{}: {}\".format(y_val, y_label), loc=\"left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cls in range(n_classes):\n",
    "    print(\"=\" * 95)\n",
    "    print('LABEL: {} \"{}\"'.format(cls, class_labels[str(cls)]))\n",
    "    print('COUNT: {}'.format(y_train[y_train==cls].shape[0]))\n",
    "    class_xs = X_train[y_train==cls]\n",
    "    visualize_class(class_xs[np.random.choice(class_xs.shape[0], size=12)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(images):\n",
    "    \"\"\"\n",
    "    1. Convert each image to grayscale and equalize histogram\n",
    "    2. Normalize image values and set the mean to zero\n",
    "    \"\"\"\n",
    "    out = np.empty(images.shape[:3], dtype=np.float32)\n",
    "    for idx in range(out.shape[0]):\n",
    "        out[idx] = cv2.equalizeHist(cv2.cvtColor(images[idx], cv2.COLOR_RGB2GRAY))\n",
    "        out[idx] = cv2.normalize(out[idx], out[idx], alpha=-0.5, beta=0.5,\n",
    "                                 norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    return out.reshape(out.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocess data and copy y_labels to avoid shuffling original data during training\n",
    "X_train_process, y_train_process = preprocess(X_train), np.copy(y_train)\n",
    "X_valid_process, y_valid_process = preprocess(X_valid), np.copy(y_valid)\n",
    "X_test_process, y_test_process = preprocess(X_test), np.copy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in range(3):\n",
    "    rand_indices = np.random.choice(X_train.shape[0], size=12)\n",
    "    subset_unprocessed = X_train[rand_indices]\n",
    "    subset_processed = X_train_process[rand_indices]\n",
    "    visualize_class(subset_unprocessed)\n",
    "    visualize_class(subset_processed.reshape(subset_processed.shape[:3]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "EPOCHS = 101\n",
    "BATCH_SIZE = 256\n",
    "LEARN_RATE = 0.001\n",
    "SAVE_FILE = \"./dataset/model.ckpt\"\n",
    "\n",
    "# Store layers weight & bias\n",
    "weight_var = lambda w_shape: tf.Variable(tf.truncated_normal(w_shape, mean=0, stddev=0.1), name=\"weights\")\n",
    "bias_var = lambda n_vars: tf.Variable(tf.zeros(n_vars), name=\"biases\")\n",
    "\n",
    "def conv2d(layer, W, b, strides=1):\n",
    "    out = tf.nn.conv2d(layer, W, strides=(1,strides,strides,1), padding=\"SAME\")\n",
    "    out = tf.nn.bias_add(out, b)\n",
    "    return tf.nn.relu(out, name=\"relu\")\n",
    "\n",
    "def pool(layer, k=2):\n",
    "    return tf.nn.max_pool(layer, ksize=(1,k,k,1), strides=(1,k,k,1), padding=\"SAME\", name=\"pool\")\n",
    "\n",
    "def fully_connected(layer, W, b, activate=True):\n",
    "    out = tf.add(tf.matmul(layer, W), b)\n",
    "    if activate:\n",
    "        out = tf.nn.relu(out, name=\"relu\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "def Model(X_inputs):\n",
    "    # Layer 1: Convolutional. Input = 32x32x1.\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        conv1 = conv2d(X_inputs, weight_var((5,5,1,32)), bias_var(32)) # Output = 32x32x32.\n",
    "        conv1 = pool(conv1, k=2) # Output = 16x16x32.\n",
    "\n",
    "    # Layer 2: Convolutional.\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        conv2 = conv2d(conv1, weight_var((5,5,32,64)), bias_var(64)) # Output = 16x16x64.\n",
    "        conv2 = pool(conv2, k=2) # Output = 8x8x64.\n",
    "    \n",
    "    # Layer 3: Convolutional.\n",
    "    with tf.variable_scope(\"conv3\"):\n",
    "        conv3 = conv2d(conv2, weight_var((5,5,64,128)), bias_var(128)) # Output = 8x8x128.\n",
    "        conv3 = pool(conv3, k=2) # Output = 4x4x128.\n",
    "\n",
    "    # Layer 4: Flatten, Pool & Concatenate Layers.\n",
    "    with tf.variable_scope(\"flat\"):\n",
    "        try:\n",
    "            # TensorFlow v1.0.1: tf.concat(values, axis);\n",
    "            flat = tf.concat((flatten(pool(conv1, k=4)),\n",
    "                              flatten(pool(conv2, k=2)),\n",
    "                              flatten(conv3)), 1) # Output 3584.\n",
    "        # Prior TF versions: tf.concat(axis, values) :D\n",
    "        except:\n",
    "            flat = tf.concat(1, (flatten(pool(conv1, k=4)),\n",
    "                              flatten(pool(conv2, k=2)),\n",
    "                              flatten(conv3))) # Output 3584.\n",
    "        flat = tf.nn.dropout(flat, keep_prob=keep_prob)\n",
    "\n",
    "    # Layer 5: Fully Connected.\n",
    "    with tf.variable_scope(\"fc1\"):\n",
    "        fc1 = fully_connected(flat, weight_var((3584,1024)), bias_var(1024)) # Output = 1024.\n",
    "        fc1 = tf.nn.dropout(fc1, keep_prob=keep_prob)\n",
    "\n",
    "    # Layer 6: Fully Connected. Out.\n",
    "    with tf.variable_scope(\"fc2\"):\n",
    "        return fully_connected(fc1, weight_var((1024,43)), bias_var(43), activate=False) # Output = 43."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_vals = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y_vals = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y_vals, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = Model(X_vals)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARN_RATE)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_labels):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_labels[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={X_vals: batch_x, y_vals: batch_y, keep_prob: 1.})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train_process)\n",
    "    for i in range(EPOCHS):\n",
    "        X_train_process, y_train_process = shuffle(X_train_process, y_train_process)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train_process[offset:end], y_train_process[offset:end]\n",
    "            sess.run(training_operation, feed_dict={X_vals: batch_x, y_vals: batch_y, keep_prob: 0.50})\n",
    "        validation_accuracy = evaluate(X_valid_process, y_valid_process)\n",
    "        if i % 10 == 0:\n",
    "            print(\"EPOCH {}: Validation Accuracy = {:.3f}\".format(i, validation_accuracy))\n",
    "    saver.save(sess, SAVE_FILE)\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf.train.Saver().restore(sess, SAVE_FILE)\n",
    "    test_accuracy = evaluate(X_test_process, y_test_process)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sign_classes = np.array([7, 9, 11, 17, 25, 31, 40])\n",
    "n_signs = len(sign_classes)\n",
    "sign_data = np.empty((n_signs,32,32,3), dtype=np.uint8)\n",
    "sign_path = \"./signs/{}.jpg\"\n",
    "\n",
    "for i, label in enumerate(sign_classes):\n",
    "    sign_data[i] = cv2.cvtColor(cv2.imread(sign_path.format(label), cv2.IMREAD_COLOR),\n",
    "                                cv2.COLOR_BGR2RGB)\n",
    "sign_data_process = preprocess(sign_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_class(sign_data, sign_classes, maxtitlelen=10, figsize=(20, 2))\n",
    "visualize_class(sign_data_process.reshape(sign_data_process.shape[:3]), figsize=(20, 2), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_preds = 5\n",
    "prediction_operation = tf.nn.top_k(tf.nn.softmax(logits), n_preds)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, SAVE_FILE)\n",
    "    probs, pred_classes = sess.run(prediction_operation,\n",
    "                                   feed_dict={X_vals: sign_data_process, keep_prob: 1.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prediction_confidence(img, likelihoods, predictions):\n",
    "    labels = [\"{:.4f}% : {}\".format(likelihoods[i]*100, class_labels[str(c)])\n",
    "              for i, c in enumerate(predictions)]\n",
    "    y_pos = np.arange(len(labels))\n",
    "\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.subplot(121, xticks=[], yticks=[])\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(122)\n",
    "    plt.barh(y_pos, likelihoods)\n",
    "    plt.yticks(y_pos, labels, position=(1.2,1), ha=\"left\", weight=\"semibold\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in range(n_preds):\n",
    "    prediction_confidence(sign_data[idx], probs[idx], pred_classes[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf.train.Saver().restore(sess, SAVE_FILE)\n",
    "    new_img_accuracy = evaluate(sign_data_process, sign_classes)\n",
    "    print(\"New Image Accuracy = {:.3f}\".format(new_img_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Visualize the Neural Network's State with Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outputFeatureMap(session, image_input, tf_activation, rows=6, cols=8, figsize=(15,25), activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    \"\"\"\n",
    "    image_input:\n",
    "        the test image being fed into the network to produce the feature maps\n",
    "    tf_activation:\n",
    "        should be a tf variable name used during your training procedure that\n",
    "        represents the calculated state of a specific weight layer\n",
    "    activation_min/max:\n",
    "        can be used to view the activation contrast in more detail, by default\n",
    "        matplot sets min and max to the actual min and max values of the output\n",
    "    plt_num:\n",
    "        used to plot out multiple different weight feature map sets on the same block,\n",
    "        just extend the plt number for each new feature map entry\n",
    "    \"\"\"\n",
    "    activation = tf_activation.eval(session=session)\n",
    "    featuremaps = activation.shape[-1]\n",
    "    assert rows*cols == featuremaps, \"expected {}*{} to equal {}\".format(rows, cols, featuremaps)\n",
    "    \n",
    "    print(\"=\" * 75)\n",
    "    print(tf_activation)\n",
    "    print()\n",
    "\n",
    "    plt.figure(plt_num, figsize=figsize)\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(rows, cols, featuremap+1)\n",
    "        plt.axis(\"off\")\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:,featuremap], interpolation=\"nearest\", vmin=activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:,featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:,featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:,featuremap], interpolation=\"nearest\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1_weights,_ = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"conv1_1\")\n",
    "conv2_weights,_ = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"conv2_1\")\n",
    "conv3_weights,_ = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"conv3_1\")\n",
    "\n",
    "sign_img = sign_data_process[0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, SAVE_FILE)\n",
    "    outputFeatureMap(sess, sign_img, conv1_weights, rows=4, cols=8, figsize=(5,5))\n",
    "    outputFeatureMap(sess, sign_img, conv2_weights, rows=16, cols=4, plt_num=2, figsize=(5,6))\n",
    "    outputFeatureMap(sess, sign_img, conv3_weights, rows=32, cols=4, plt_num=3, figsize=(9,9))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
